%%% my citations

@ARTICLE{lstm-pytorch,
    author = {Sak, Hasim 
        and Senior, Andrew W. 
        and Beaufays, Fran{\c{c}}oise},
    title = {{Long Short-Term Memory Based Recurrent Neural Network Architectures
                  for Large Vocabulary Speech Recognition}},
    journal = {{arXiv:1402.1128 [cs.NE]}},
    pages = {1--5},
    year = {2014},
    eprinttype    = {arXiv},
    eprint       = {1402.1128},
}

@ARTICLE{lstm,
    author = {Hochreiter, Sepp and Schmidhuber, Jürgen},
primaryClass={cs.NE},
    year = {1997},
    month = {12},
    pages = {1735-80},
    title = {{Long Short-term Memory}},
    volume = {9},
    journal = {Neural computation},
    doi = {10.1162/neco.1997.9.8.1735},
}

@inproceedings{lmu,
    author = {Voelker, Aaron and Kaji\'{c}, Ivana and Eliasmith, Chris},
    booktitle = {Proc. of Conf. Advances in Neural Information Processing Systems (NIPS)},
    pages = {15544-15553},
    title = {{Legendre Memory Units: Continuous-Time Representation in Recurrent Neural Networks}},
    location={Vancouver, Canada},
    year = {2019},
    url = {https://papers.nips.cc/paper_files/paper/2019/file/952285b9b7e7a1be5aa7849f32ffff05-Paper.pdf},
  urldate={2024-07-24},
}

@misc{torch-lmu,
    author = {Varma, Harschit},
    title = {pytorch-lmu},
    year = {2021},
    publisher = {GitHub},
    journal = {GitHub repository},
    howpublished = {\url{https://github.com/hrshtv/pytorch-lmu}},
    commit = {95a0b937c16b18cc8469e6e86440aa8dcb006726}
}

@inproceedings{xu2018collision,
  author    = {Kaiping Xu and Zheng Qin and Guolong Wang and Kai Huang and Shuxiong Ye and Huidi Zhang},
  title     = {{Collision-Free LSTM for Human Trajectory Prediction}},
  booktitle = {Proceedings of the International Conference on Multimedia Modeling},
  pages     = {106--116},
  year      = {2018},
  publisher = {Springer},
  address   = {Cham},
  doi       = {10.1007/978-3-319-73603-7_9},
  isbn      = {978-3-319-73602-0},
}

@article{BitNet2023,
  title={{BitNet: Scaling 1-bit Transformers for Large Language Models}},
  author={Wang, Hongyu and Ma, Shuming and Dong, Li and Huang, Shaohan and Wang, Huaijie and Ma, Lingxiao and Yang, Fan and Wang, Ruiping and Wu, Yi and Wei, Furu},
  journal={arXiv preprint arXiv:2310.11453},
primaryClass={cs.CL},
  year={2023},
    eprinttype    = {arXiv},
    eprint       = {2310.11453},
}

@article{llama,
  title={{LLaMA: Open and Efficient Foundation Language Models}},
  author={Meta AI},
  journal = {	arXiv:2302.13971},
  year={2023},
  eprinttype    = {arXiv},
  eprint       = {2302.13971},
primaryClass={cs.CL},
  month={2},
}

@article{gpt,
  primaryClass={cs.CL},
  title={{GPT-4 Technical Report}},
  author={OpenAI},
  journal={arXiv:2303.08774v6},
  year={2024},
  month={4},
  eprinttype    = {arXiv},
  eprint       = {2303.08774},
}

@article{gemini,
primaryClass={cs.CL},
  title={{Gemini: A Family of Highly Capable Multimodal Models}},
  author={Gemini Team Google},
  journal={arXiv:2312.11805v4},
  eprinttype    = {arXiv},
  eprint       = {2312.11805v4},
  year={2024},
  month = {6},
}

@misc{claude,
  title={Claude: An AI Assistant by Anthropic},
  author={Anthropic},
  year={2023},
  month = {3},
  url={https://www.anthropic.com/news/claude-3-family},
  urldate={2024-07-24}
}

@article{transformer,
 author       = {Ashish Vaswani and
                  Noam Shazeer and
                  Niki Parmar and
                  Jakob Uszkoreit and
                  Llion Jones and
                  Aidan N. Gomez and
                  Lukasz Kaiser and
                  Illia Polosukhin},
  title        = {Attention Is All You Need},
  journal      = {Computation and Language},
  volume       = {abs/1706.03762},
  year         = {2017},
  month = {8},
primaryClass={cs.CL},
  eprinttype    = {arXiv},
  eprint       = {1706.03762},
  biburl       = {https://dblp.org/rec/journals/corr/VaswaniSPUJGKP17.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@article{bert,
      title={BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding}, 
      author={Jacob Devlin and Ming-Wei Chang and Kenton Lee and Kristina Toutanova},
      year={2019},
      eprint={1810.04805},
        Journal = {{ArXiv}},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/1810.04805}, 
}

@mastersthesis{gosalci,
author = {Denis Gosalci},
title = {{Legendre Memory Unit}},
school = {Technische Hochschule Georg-Simon-Ohm N{\"u}rnberg},
year = {2021},
type={Bachelor's Thesis},
}

@phdthesis{diss_tobi,
author = {Tobias Feigl},
title = {{
Datengetriebene Methoden zur Bestimmung von Position und 
Orientierung in funk‐ und trägheitsbasierter Koppelnavigation}},
school = {{
Technische Fakultät der Friedrich‐-Alexander‐-Universität Erlangen-‐Nürnberg
}},
year = {2021},
type = {Dr.-Ing. Dissertation},
}

@article{RetNet,
author = {Yutao Sun and Li Dong and Shaohan Huang and Shuming Ma and Yuqing Xia and Jilong Xue and Jianyong Wang and Furu Wei},
title={{Retentive Network: A Successor to Transformer for Large Language Models}}, 
journal = {arXiv: 2307.08621 [cs.CL]},
year={2023},
pages = {1-14},
doi = {10.48550/arXiv.2307.08621},
}

@inproceedings{MBT,
author={Hauri, Sandro and Djuric, Nemanja and Radosavljevic, Vladan and Vucetic, Slobodan},
booktitle={{Proc. of IEEE Winter Conf. on Applications of Computer Vision (WACV)}}, 
title={{Multi-Modal Trajectory Prediction of NBA Players}}, 
year={2021},
pages={1639-1648},
doi={10.1109/WACV48630.2021.00168},
location={Waikoloa, HI}
}

@article{timegpt,
      title={{TimeGPT-1}}, 
      author={Azul Garza and Max Mergenthaler-Canseco},
      year={2023},
journal = {{ArXiv}},
month = {5},
      eprint={2310.03589},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
}

@article{giuliari2020transformer,
title={{Transformer Networks for Trajectory Forecasting}}, 
author={Francesco Giuliari and Irtiza Hasan and Marco Cristani and Fabio Galasso},
year={2020},
journal={arXiv:2003.08111 [cs.CV]},
doi={10.48550/arXiv.2003.08111},
pages = {1-14},
}

@article{advantages1,
author = {L. Lamas and J. Barrera and G. Otranto and C. Ugrinowitsch},
title = {{Invasion Team Sports: Strategy and Match Modeling}},
journal = {Intl. Jo. of Performance Analysis in Sport},
year = {2014},
volume = {14},
number = {1},
pages = {307--329},
doi = {10.1080/24748668.2014.11868723},
}

@article{postgame,
author = {J. Gudmundsson and M. Horton},
title = {{Spatio-Temporal Analysis of Team Sports}},
journal = {ACM Computing Surveys (CSUR)},
year = {2017},
volume = {50},
number = {2},
pages = {1-42},
doi = {10.48550/arXiv.1602.06994}
}

@article{baevski2020,
  author       = {Alexei Baevski and
                  Henry Zhou and
                  Abdelrahman Mohamed and
                  Michael Auli},
  title        = {wav2vec 2.0: {A} Framework for Self-Supervised Learning of Speech
                  Representations},
  journal      = {CoRR},
  volume       = {abs/2006.11477},
  year         = {2020},
month={10},
  eprinttype    = {arXiv},
  eprint       = {2006.11477},
      primaryClass={cs.CL},
}


@article{linouk,
    author = {Linou, Kostya and Linou, Dzimitryi and de Boer, Martijn },
    title = {{NBA-Player-Movements}},
    year = {2016},
    month = {8}, 
    publisher = {GitHub},
    journal = {GitHub repository},
    howpublished = {GitHub repository, commit \texttt{f7d4cf2c7e607029abfd5715a0d4073bedae328e}},
    url = {https://github.com/linouk23/NBA-Player-Movements},
    commit = {f7d4cf2c7e607029abfd5715a0d4073bedae328e}
}

@software{Gosalci_master_den_2024,
author = {Gosalci, B.Sc., Denis},
doi = {10.5281/zenodo.13332149},
license = {MIT},
month = aug,
title = {{master\_den}},
url = {https://github.com/va42xuqi/master_den.git},
version = {v.1.1.0},
year = {2024}
}

@ARTICLE{pan2009survey,
  author={Pan, Sinno Jialin and Yang, Qiang},
  journal={IEEE Transactions on Knowledge and Data Engineering}, 
  title={{A Survey on Transfer Learning}}, 
  year={2010},
  volume={22},
  number={10},
  pages={1345-1359},
  keywords={Machine learning;Training data;Data mining;Knowledge transfer;Space technology;Knowledge engineering;Machine learning algorithms;Labeling;Learning systems;Testing;Transfer learning;survey;machine learning;data mining.},
  doi={10.1109/TKDE.2009.191}}


@Book{GoodBengCour16,
  Title                    = {{Deep Learning}},
  Author                   = {Ian J. Goodfellow and Yoshua Bengio and Aaron Courville},
  Publisher                = {MIT Press},
  Year                     = {2016},
  Address                  = {Cambridge, MA, USA},
  Note                     = {\url{http://www.deeplearningbook.org}}
}

@techreport{radford2019language,
  author    = {Alec Radford and Jeff Wu and Ilya Sutskever},
  title     = {{Language Models are Unsupervised Multitask Learners}},
  institution = {{OpenAI}},
  year      = {2019},
  url       = {https://www.semanticscholar.org/paper/Language-Models-are-Unsupervised-Multitask-Learners-Radford-Wu/9405cc0d6169988371b2755e573cc28650d14dfe},
  note      = {{Corpus ID: 160025533}}
}

@misc{lstm-pytorch2,
  author       = {{PyTorch}},
  title        = {{torch.nn.LSTM}},
  howpublished = {\url{https://pytorch.org/docs/stable/generated/torch.nn.LSTM.html}},
  year         = {2024},
  note         = {Accessed: 2024-09-12}
}

@misc{adam,
      title={Adam: A Method for Stochastic Optimization}, 
      author={Diederik P. Kingma and Jimmy Ba},
      year={2017},
      eprint={1412.6980},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/1412.6980}, 
}

@software{codecarbon,
  author       = {Benoit Courty and
                  Victor Schmidt and
                  Sasha Luccioni and
                  Goyal-Kamal and
                  MarionCoutarel and
                  Boris Feld and
                  Jérémy Lecourt and
                  LiamConnell and
                  Amine Saboni and
                  Inimaz and
                  supatomic and
                  Mathilde Léval and
                  Luis Blanche and
                  Alexis Cruveiller and
                  ouminasara and
                  Franklin Zhao and
                  Aditya Joshi and
                  Alexis Bogroff and
                  Hugues de Lavoreille and
                  Niko Laskaris and
                  Edoardo Abati and
                  Douglas Blank and
                  Ziyao Wang and
                  Armin Catovic and
                  Marc Alencon and
                  Michał Stęchły and
                  Christian Bauer and
                  Lucas Otávio N. de Araújo and
                  JPW and
                  MinervaBooks},
  title        = {{mlco2/codecarbon: v2.4.1}},
  month        = may,
  year         = 2024,
  publisher    = {Zenodo},
  version      = {v2.4.1},
  doi          = {10.5281/zenodo.11171501},
  url          = {https://doi.org/10.5281/zenodo.11171501}
}

@misc{adamw,
      title={{Decoupled Weight Decay Regularization}}, 
      author={Ilya Loshchilov and Frank Hutter},
      year={2019},
      eprint={1711.05101},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/1711.05101}, 
}

@misc{bloom,
  title={{BLOOM: A 176B-Parameter Open-Access Multilingual Language Model}},
  author={{BigScience Workshop}},
  year={2023},
  eprint={2211.05100},
  archivePrefix={arXiv},
  primaryClass={cs.CL},
  url={https://arxiv.org/abs/2211.05100}
}

@misc{opt,
      title={OPT: Open Pre-trained Transformer Language Models}, 
      author={Susan Zhang and Stephen Roller and Naman Goyal and Mikel Artetxe and Moya Chen and Shuohui Chen and Christopher Dewan and Mona Diab and Xian Li and Xi Victoria Lin and Todor Mihaylov and Myle Ott and Sam Shleifer and Kurt Shuster and Daniel Simig and Punit Singh Koura and Anjali Sridhar and Tianlu Wang and Luke Zettlemoyer},
      year={2022},
      eprint={2205.01068},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2205.01068}, 
}

@misc{rapach2020,
      title={Stock Market Prediction via Deep Learning Techniques: A Survey}, 
      author={Jinan Zou and Qingying Zhao and Yang Jiao and Haiyao Cao and Yanxi Liu and Qingsen Yan and Ehsan Abbasnejad and Lingqiao Liu and Javen Qinfeng Shi},
      year={2023},
      eprint={2212.12717},
      archivePrefix={arXiv},
      primaryClass={q-fin.GN},
      url={https://arxiv.org/abs/2212.12717}, 
}
@INPROCEEDINGS{ribeiro2021,
  author={Zhang, Wenjie and Cheema, Farwa and Srinivasan, Dipti},
  booktitle={2018 IEEE PES Asia-Pacific Power and Energy Engineering Conference (APPEEC)}, 
  title={Forecasting of Electricity Prices Using Deep Learning Networks}, 
  year={2018},
  volume={},
  number={},
  pages={451-456},
  keywords={Time series analysis;Forecasting;Predictive models;Data models;Estimation;Load modeling},
  doi={10.1109/APPEEC.2018.8566313}}

@article{mills2019,
author = {Jain, Garima and Singh, Sanjeev},
year = {2016},
month = {12},
pages = {177-180},
title = {A Review on Weather Forecasting Techniques},
volume = {5},
journal = {IJARCCE},
doi = {10.17148/IJARCCE.2016.51237}
}

@INPROCEEDINGS{social-lstm,
  author={Alahi, Alexandre and Goel, Kratarth and Ramanathan, Vignesh and Robicquet, Alexandre and Fei-Fei, Li and Savarese, Silvio},
  booktitle={2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)}, 
  title={Social LSTM: Human Trajectory Prediction in Crowded Spaces}, 
  year={2016},
  volume={},
  number={},
  pages={961-971},
  keywords={Trajectory;Predictive models;Recurrent neural networks;Videos;Forecasting;Navigation;Atmospheric modeling},
  doi={10.1109/CVPR.2016.110}}

@article{dosovitskiy2020,
  title={An image is worth 16x16 words: Transformers for image recognition at scale},
  author={Dosovitskiy, Alexey and Beyer, Laura and Kolesnikov, Alexander and Weissenborn, Dirk and Schiele, Bernt},
  journal={arXiv preprint arXiv:2010.11929},
  year={2020}
}

@inproceedings{carion2020,
  title={End-to-end object detection with transformers},
  author={Carion, Nicolas and Massa, Francisco and Synnaeve, Gabriel and Cadene, Romain and Schmid, Cordelia},
  booktitle={European Conference on Computer Vision (ECCV)},
  year={2020}
}

@inproceedings{parisotto2017,
  title={Neural map: Structured memory for deep reinforcement learning},
  author={Parisotto, Emilien and Salakhutdinov, Ruslan},
  booktitle={arXiv preprint arXiv:1702.08360},
  year={2017}
}

@inproceedings{choromanski2020,
  title={End-to-end speech recognition with transformers},
  author={Choromanski, Krzysztof and et al.},
  booktitle={Interspeech},
  year={2020}
}

@inproceedings{velickovic2018,
  title={Graph attention networks},
  author={Veličković, Petar and Cucurull, Guillem and Casanova, Alberto and Romero, Angel and Liò, Pietro},
  booktitle={International Conference on Learning Representations (ICLR)},
  year={2018}
}

@article{chen2018,
  title={Attention-based multimodal fusion for video captioning},
  author={Chen, Yu and et al.},
  journal={ACM Transactions on Multimedia Computing, Communications, and Applications},
  year={2018}
}